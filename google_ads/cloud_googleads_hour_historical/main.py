"""
Google Ads ‚Üí BigQuery (Cloud Function) - DADOS HOR√ÅRIOS HIST√ìRICOS
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Coleta m√©tricas hor√°rias por campanha de ONTEM:
- date, hour, account_id, account_name, campaign_id, campaign_name
- spend, clicks, cpc, impressions, ctr, conversions, cost_per_conversion
- moeda, budget

Resultado final = m√©tricas por hora por campanha (dados de ontem)
ADICIONA os dados no BigQuery (WRITE_APPEND)

‚ö†Ô∏è Este script roda diariamente √†s 10h AM (hor√°rio do Brasil) para coletar dados de ontem.

‚ö†Ô∏è NOTAS SOBRE GRPC E GITHUB ACTIONS:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
O Google Ads API usa GRPC por padr√£o, que pode ter problemas de rede
no GitHub Actions. Implementamos as seguintes solu√ß√µes:

1. Retry logic com backoff exponencial (3 tentativas)
2. Delay de 1 segundo entre requisi√ß√µes de contas diferentes
3. Configura√ß√µes de ambiente GRPC otimizadas
4. use_proto_plus=True (formato compat√≠vel)
5. Verifica√ß√£o pr√©via de todos os secrets

Se algumas contas falharem com erro "GRPC target method can't be resolved",
o script continua processando as outras contas e salva os dados que conseguiu coletar.
"""

import json
import time
import os
from datetime import datetime, timedelta
from google.oauth2 import service_account
from google.ads.googleads.client import GoogleAdsClient
from google.cloud import bigquery
import pytz
import pandas as pd
import logging
from google.api_core import retry
from google.api_core import exceptions as core_exceptions

# ------------------------------------------------------------------------------
# CONFIGURA√á√ïES
# ------------------------------------------------------------------------------
# Configurar vari√°veis de ambiente para melhorar estabilidade do GRPC
os.environ['GRPC_ENABLE_FORK_SUPPORT'] = '1'
os.environ['GRPC_POLL_STRATEGY'] = 'poll'
# Aumentar timeout do GRPC (30 segundos)
os.environ['GRPC_PYTHON_LOG_LEVEL'] = 'ERROR'

logging.basicConfig(
    level=logging.INFO,
    handlers=[logging.StreamHandler()]
)

logger = logging.getLogger(__name__)

# üîπ Configura√ß√£o do BigQuery
BIGQUERY_TABLE_ID = "data-v1-423414.test.cloud_googleads_hour_historical"
sao_paulo_tz = pytz.timezone('America/Sao_Paulo')

# Data de ontem em S√£o Paulo
ontem = (datetime.now(sao_paulo_tz) - timedelta(days=1)).strftime('%Y-%m-%d')

# IDs das contas do Google Ads
CUSTOMER_IDS = [
    "9679496200", #001
    "1378108795", #002
    "2153708041", #003
    "5088162800", #004
    "7205935192", #005
    "4985450045", #006
    "4161586974", #007
    "5074252268", #008
    "8581304094", #009
    "2722606250", #010
]

# ------------------------------------------------------------------------------
# DIAGN√ìSTICO DE VERS√ïES
# ------------------------------------------------------------------------------
def log_library_versions():
    """
    Loga as vers√µes das bibliotecas principais para debug.
    √ötil para identificar se vers√µes antigas est√£o causando problemas.
    """
    logger.info("=" * 80)
    logger.info("üìö VERS√ïES DAS BIBLIOTECAS INSTALADAS")
    logger.info("=" * 80)
    
    # google-ads - usar pkg_resources pois n√£o tem __version__ direto
    try:
        import pkg_resources
        ga_version = pkg_resources.get_distribution('google-ads').version
        logger.info(f"‚úÖ google-ads: {ga_version}")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è google-ads: Erro ao obter vers√£o - {e}")
    
    # grpcio
    try:
        import grpc
        logger.info(f"‚úÖ grpcio: {grpc.__version__}")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è grpcio: Erro ao obter vers√£o - {e}")
    
    # google-api-core
    try:
        import google.api_core
        logger.info(f"‚úÖ google-api-core: {google.api_core.__version__}")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è google-api-core: Erro ao obter vers√£o - {e}")
    
    # google-cloud-bigquery
    try:
        import google.cloud.bigquery
        logger.info(f"‚úÖ google-cloud-bigquery: {google.cloud.bigquery.__version__}")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è google-cloud-bigquery: Erro ao obter vers√£o - {e}")
    
    # protobuf
    try:
        import pkg_resources
        pb_version = pkg_resources.get_distribution('protobuf').version
        logger.info(f"‚úÖ protobuf: {pb_version}")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è protobuf: Erro ao obter vers√£o - {e}")
    
    logger.info("=" * 80 + "\n")

# ------------------------------------------------------------------------------
# VERIFICA√á√ÉO DE SECRETS E CREDENCIAIS
# ------------------------------------------------------------------------------
def verify_secrets():
    """
    Verifica se todos os secrets necess√°rios est√£o configurados corretamente.
    Retorna True se tudo estiver OK, False caso contr√°rio.
    """
    logger.info("=" * 80)
    logger.info("üîç VERIFICANDO CONFIGURA√á√ÉO DE SECRETS E CREDENCIAIS")
    logger.info("=" * 80)
    
    all_ok = True
    
    # 1. Verificar SECRET_GOOGLE_SERVICE_ACCOUNT ou GOOGLE_APPLICATION_CREDENTIALS
    logger.info("\nüìã 1/3 - Verificando credenciais do Google Cloud...")
    secret_json = os.getenv("SECRET_GOOGLE_SERVICE_ACCOUNT")
    creds_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
    
    if secret_json:
        logger.info("   ‚úÖ SECRET_GOOGLE_SERVICE_ACCOUNT encontrado")
        try:
            service_account_info = json.loads(secret_json)
            required_keys = ["type", "project_id", "private_key_id", "private_key", "client_email"]
            missing_keys = [key for key in required_keys if key not in service_account_info]
            if missing_keys:
                logger.error(f"   ‚ùå Campos faltando no SECRET_GOOGLE_SERVICE_ACCOUNT: {missing_keys}")
                all_ok = False
            else:
                logger.info(f"   ‚úÖ JSON v√°lido com todos os campos necess√°rios")
                logger.info(f"   ‚úÖ Project ID: {service_account_info.get('project_id', 'N/A')}")
                logger.info(f"   ‚úÖ Client Email: {service_account_info.get('client_email', 'N/A')}")
        except json.JSONDecodeError as e:
            logger.error(f"   ‚ùå Erro ao fazer parse do SECRET_GOOGLE_SERVICE_ACCOUNT: {e}")
            all_ok = False
    elif creds_path:
        if os.path.exists(creds_path):
            logger.info(f"   ‚úÖ GOOGLE_APPLICATION_CREDENTIALS encontrado: {creds_path}")
        else:
            logger.error(f"   ‚ùå GOOGLE_APPLICATION_CREDENTIALS definido mas arquivo n√£o existe: {creds_path}")
            all_ok = False
    else:
        logger.warning("   ‚ö†Ô∏è Nenhuma credencial expl√≠cita encontrada, tentar√° usar Application Default Credentials")
    
    # 2. Verificar SECRET_GOOGLE_ADS_CONFIG
    logger.info("\nüìã 2/3 - Verificando configura√ß√£o do Google Ads...")
    ads_config_json = os.getenv("SECRET_GOOGLE_ADS_CONFIG")
    
    if not ads_config_json:
        logger.error("   ‚ùå SECRET_GOOGLE_ADS_CONFIG n√£o encontrado!")
        all_ok = False
    else:
        logger.info(f"   ‚úÖ SECRET_GOOGLE_ADS_CONFIG encontrado ({len(ads_config_json)} caracteres)")
        
        # Tentar fazer parse
        try:
            # Aplicar corre√ß√µes de formato
            ads_config_json_fixed = ads_config_json.replace(': True', ': true')
            ads_config_json_fixed = ads_config_json_fixed.replace(': False', ': false')
            ads_config_json_fixed = ads_config_json_fixed.replace(':True', ':true')
            ads_config_json_fixed = ads_config_json_fixed.replace(':False', ':false')
            
            config = json.loads(ads_config_json_fixed)
            
            # Verificar campos obrigat√≥rios
            required_fields = ["developer_token", "client_id", "client_secret", "refresh_token", "login_customer_id"]
            missing_fields = [field for field in required_fields if field not in config]
            
            if missing_fields:
                logger.error(f"   ‚ùå Campos obrigat√≥rios faltando: {missing_fields}")
                all_ok = False
            else:
                logger.info("   ‚úÖ Todos os campos obrigat√≥rios presentes")
                logger.info(f"   ‚úÖ developer_token: {config['developer_token'][:10]}...")
                logger.info(f"   ‚úÖ client_id: {config['client_id'][:30]}...")
                logger.info(f"   ‚úÖ login_customer_id: {config['login_customer_id']}")
                logger.info(f"   ‚ÑπÔ∏è use_proto_plus (original): {config.get('use_proto_plus', 'n√£o definido')}")
                
        except json.JSONDecodeError as e:
            logger.error(f"   ‚ùå Erro ao fazer parse do JSON: {e}")
            logger.error(f"   ‚ùå Posi√ß√£o do erro: linha {e.lineno}, coluna {e.colno}")
            all_ok = False
        except Exception as e:
            logger.error(f"   ‚ùå Erro ao validar configura√ß√£o: {e}")
            all_ok = False
    
    # 3. Verificar Customer IDs
    logger.info("\nüìã 3/3 - Verificando Customer IDs...")
    if CUSTOMER_IDS:
        logger.info(f"   ‚úÖ {len(CUSTOMER_IDS)} Customer IDs configurados:")
        for cid in CUSTOMER_IDS:
            logger.info(f"      - {cid}")
    else:
        logger.error("   ‚ùå Nenhum Customer ID configurado!")
        all_ok = False
    
    # Resumo
    logger.info("\n" + "=" * 80)
    if all_ok:
        logger.info("‚úÖ TODOS OS SECRETS E CONFIGURA√á√ïES EST√ÉO OK!")
    else:
        logger.error("‚ùå PROBLEMAS ENCONTRADOS NA CONFIGURA√á√ÉO!")
        logger.error("   Por favor, verifique os secrets no GitHub Actions")
    logger.info("=" * 80 + "\n")
    
    return all_ok

# ------------------------------------------------------------------------------
# CONFIGURA√á√ÉO DE CREDENCIAIS
# ------------------------------------------------------------------------------
def get_google_credentials():
    """
    Obt√©m credenciais do Google Cloud a partir de vari√°veis de ambiente.
    Prioridade:
    1. SECRET_GOOGLE_SERVICE_ACCOUNT (JSON string)
    2. GOOGLE_APPLICATION_CREDENTIALS (caminho para arquivo JSON)
    3. Application Default Credentials
    """
    try:
        # Tentar obter do SECRET_GOOGLE_SERVICE_ACCOUNT (GitHub Actions)
        secret_json = os.getenv("SECRET_GOOGLE_SERVICE_ACCOUNT")
        if secret_json:
            logger.info("‚úÖ Usando credenciais do SECRET_GOOGLE_SERVICE_ACCOUNT")
            service_account_info = json.loads(secret_json)
            return service_account.Credentials.from_service_account_info(service_account_info)
        
        # Tentar obter do GOOGLE_APPLICATION_CREDENTIALS (arquivo JSON)
        creds_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
        if creds_path and os.path.exists(creds_path):
            logger.info("‚úÖ Usando credenciais do arquivo: %s", creds_path)
            return service_account.Credentials.from_service_account_file(creds_path)
        
        # Fallback para Application Default Credentials
        logger.info("‚úÖ Usando Application Default Credentials")
        return None  # BigQuery Client usar√° as credenciais padr√£o
        
    except Exception as e:
        logger.error("‚ùå Erro ao obter credenciais do Google: %s", str(e))
        raise

def get_google_ads_config():
    """
    Obt√©m configura√ß√£o do Google Ads a partir de vari√°vel de ambiente.
    Inclui valida√ß√£o e corre√ß√£o autom√°tica do formato.
    """
    ads_config_json = os.getenv("SECRET_GOOGLE_ADS_CONFIG")
    if not ads_config_json:
        raise ValueError("‚ùå SECRET_GOOGLE_ADS_CONFIG n√£o encontrado nas vari√°veis de ambiente!")
    
    logger.info("‚úÖ Carregando configura√ß√£o do Google Ads do SECRET_GOOGLE_ADS_CONFIG")
    logger.info(f"   Tamanho do JSON: {len(ads_config_json)} caracteres")
    
    # Corre√ß√£o autom√°tica: substituir True/False por true/false (Python ‚Üí JSON)
    ads_config_json = ads_config_json.replace(': True', ': true')
    ads_config_json = ads_config_json.replace(': False', ': false')
    ads_config_json = ads_config_json.replace(':True', ':true')
    ads_config_json = ads_config_json.replace(':False', ':false')
    
    try:
        config = json.loads(ads_config_json)
        logger.info("‚úÖ JSON parseado com sucesso")
    except json.JSONDecodeError as e:
        logger.error(f"‚ùå Erro ao fazer parse do JSON: {e}")
        logger.error(f"   Posi√ß√£o do erro: linha {e.lineno}, coluna {e.colno}")
        logger.error(f"   Trecho: ...{ads_config_json[max(0, e.pos-50):e.pos+50]}...")
        raise ValueError(f"JSON inv√°lido no SECRET_GOOGLE_ADS_CONFIG: {e}")
    
    # Validar campos obrigat√≥rios
    required_fields = ["developer_token", "client_id", "client_secret", "refresh_token", "login_customer_id"]
    missing_fields = [field for field in required_fields if field not in config]
    
    if missing_fields:
        logger.error(f"‚ùå Campos obrigat√≥rios faltando: {missing_fields}")
        raise ValueError(f"Campos obrigat√≥rios faltando no SECRET_GOOGLE_ADS_CONFIG: {missing_fields}")
    
    # Log de informa√ß√µes ANTES da modifica√ß√£o
    logger.info(f"   ‚úÖ developer_token: {config['developer_token'][:10]}...")
    logger.info(f"   ‚úÖ client_id: {config['client_id'][:30]}...")
    logger.info(f"   ‚úÖ login_customer_id: {config['login_customer_id']}")
    logger.info(f"   üìä use_proto_plus (ORIGINAL do secret): {config.get('use_proto_plus', 'n√£o definido')}")
    
    # ‚ö†Ô∏è NOTA: use_proto_plus n√£o controla GRPC vs REST, apenas o formato das mensagens
    # Ambos os valores (True/False) usam GRPC. Vamos usar True para compatibilidade.
    config['use_proto_plus'] = True
    logger.info("   üîÑ Definindo use_proto_plus=True (formato protobuf messages)")
    logger.info(f"   ‚úÖ use_proto_plus (AP√ìS modifica√ß√£o): {config['use_proto_plus']}")
    
    # Garantir que token_uri est√° presente
    if 'token_uri' not in config:
        logger.info("   ‚ÑπÔ∏è token_uri n√£o especificado, usando padr√£o do Google")
        config['token_uri'] = "https://oauth2.googleapis.com/token"
    
    # Log final da configura√ß√£o (sem expor credenciais)
    logger.info("   üìã Configura√ß√£o final:")
    logger.info(f"      - use_proto_plus: {config['use_proto_plus']}")
    logger.info(f"      - token_uri: {config.get('token_uri', 'N/A')}")
    
    logger.info("‚úÖ Configura√ß√£o do Google Ads validada e pronta para uso")
    return config

# ------------------------------------------------------------------------------
# BIGQUERY CLIENT
# ------------------------------------------------------------------------------
bq_client = None

def get_bq_client():
    """Lazy loading do cliente BigQuery."""
    global bq_client
    if bq_client is None:
        try:
            credentials = get_google_credentials()
            if credentials:
                bq_client = bigquery.Client(
                    credentials=credentials, 
                    project=credentials.project_id if hasattr(credentials, 'project_id') else "data-v1-423414"
                )
            else:
                # Usar Application Default Credentials
                bq_client = bigquery.Client(project="data-v1-423414")
            
            logger.info("‚úÖ BigQuery client configurado com sucesso!")
        except Exception as e:
            logger.error("‚ùå Erro ao configurar BigQuery client: %s", str(e))
            bq_client = None
    return bq_client

# ------------------------------------------------------------------------------
# GOOGLE ADS CLIENT
# ------------------------------------------------------------------------------
def get_google_ads_client():
    """Cria cliente Google Ads."""
    try:
        google_ads_config = get_google_ads_config()
        client = GoogleAdsClient.load_from_dict(google_ads_config)
        logger.info("‚úÖ Google Ads client configurado com sucesso!")
        return client
    except Exception as e:
        logger.error("‚ùå Erro ao configurar Google Ads client: %s", str(e))
        raise

# ------------------------------------------------------------------------------
# FUN√á√ïES DE PROCESSAMENTO
# ------------------------------------------------------------------------------
def check_table_exists():
    """Verifica e cria tabela no BigQuery se n√£o existir."""
    bq_client = get_bq_client()
    try:
        bq_client.get_table(BIGQUERY_TABLE_ID)
        logger.info("‚úÖ Tabela encontrada no BigQuery.")
    except:
        logger.warning("‚ö†Ô∏è Tabela n√£o encontrada. Criando...")
        create_bigquery_table()

def create_bigquery_table():
    """Cria tabela no BigQuery."""
    bq_client = get_bq_client()
    dataset_id, table_name = BIGQUERY_TABLE_ID.split(".")[1:]
    dataset_ref = bq_client.dataset(dataset_id)
    table_ref = dataset_ref.table(table_name)

    schema = [
        bigquery.SchemaField("account_name", "STRING"),
        bigquery.SchemaField("account_id", "STRING"),
        bigquery.SchemaField("campaign_id", "STRING"),
        bigquery.SchemaField("campaign_name", "STRING"),
        bigquery.SchemaField("date", "DATE"),
        bigquery.SchemaField("hour", "INTEGER"),
        bigquery.SchemaField("moeda", "STRING"),
        bigquery.SchemaField("budget", "FLOAT"),
        bigquery.SchemaField("spend", "FLOAT"),
        bigquery.SchemaField("clicks", "INTEGER"),
        bigquery.SchemaField("cpc", "FLOAT"),
        bigquery.SchemaField("impressions", "INTEGER"),
        bigquery.SchemaField("ctr", "FLOAT"),
        bigquery.SchemaField("conversions", "FLOAT"),
        bigquery.SchemaField("cost_per_conversion", "FLOAT"),
        bigquery.SchemaField("imported_at", "TIMESTAMP")
    ]

    table = bigquery.Table(table_ref, schema=schema)
    try:
        bq_client.create_table(table)
        logger.info("‚úÖ Tabela %s criada com sucesso.", BIGQUERY_TABLE_ID)
        time.sleep(5)  # Aguarda propaga√ß√£o no BigQuery
    except Exception as e:
        logger.error("‚ùå Erro ao criar tabela: %s", e)

def get_google_ads_data(client, customer_id, max_retries=3):
    """
    Busca dados do Google Ads para um customer_id com retry logic.
    
    Args:
        client: Cliente Google Ads
        customer_id: ID da conta
        max_retries: N√∫mero m√°ximo de tentativas (padr√£o: 3)
    
    Returns:
        Lista de dados extra√≠dos
    """
    # Query para coletar dados de ONTEM (data anterior)
    query = f"""
        SELECT
            customer.id,
            customer.descriptive_name,
            campaign.id,
            campaign.name,
            segments.date,
            segments.hour,
            customer.currency_code,
            campaign_budget.amount_micros,
            metrics.cost_micros,
            metrics.clicks,
            metrics.average_cpc,
            metrics.impressions,
            metrics.ctr,
            metrics.conversions,
            metrics.cost_per_conversion
        FROM campaign
        WHERE segments.date = '{ontem}'
    """

    ga_service = client.get_service("GoogleAdsService")
    
    # Retry logic com backoff exponencial
    for attempt in range(1, max_retries + 1):
        try:
            logger.info(f"   üîÑ Tentativa {attempt}/{max_retries} para customer_id {customer_id}")
            
            response = ga_service.search(customer_id=customer_id, query=query)

            data = []
            # Timestamp de importa√ß√£o (hora de S√£o Paulo)
            imported_at = datetime.now(sao_paulo_tz)
            
            for row in response:
                # ‚úÖ Acesso seguro ao budget (pode n√£o existir em algumas campanhas)
                budget = 0.0
                try:
                    if hasattr(row, "campaign_budget") and hasattr(row.campaign_budget, "amount_micros"):
                        budget = float(row.campaign_budget.amount_micros) / 1_000_000
                except Exception:
                    pass
                
                data.append({
                    "account_name": row.customer.descriptive_name if hasattr(row.customer, "descriptive_name") else "",
                    "account_id": str(row.customer.id) if hasattr(row.customer, "id") else "",
                    "campaign_id": str(row.campaign.id) if hasattr(row.campaign, "id") else "",
                    "campaign_name": row.campaign.name if hasattr(row.campaign, "name") else "",
                    "date": str(row.segments.date) if hasattr(row.segments, "date") else "",
                    "hour": int(row.segments.hour) if hasattr(row.segments, "hour") else 0,
                    "moeda": row.customer.currency_code if hasattr(row.customer, "currency_code") else "",
                    "budget": budget,
                    "spend": float(row.metrics.cost_micros / 1_000_000) if hasattr(row.metrics, "cost_micros") else 0.0,
                    "clicks": int(row.metrics.clicks) if hasattr(row.metrics, "clicks") else 0,
                    "cpc": float(row.metrics.average_cpc / 1_000_000) if hasattr(row.metrics, "average_cpc") else 0.0,
                    "impressions": int(row.metrics.impressions) if hasattr(row.metrics, "impressions") else 0,
                    "ctr": float(row.metrics.ctr) if hasattr(row.metrics, "ctr") else 0.0,
                    "conversions": float(row.metrics.conversions) if hasattr(row.metrics, "conversions") else 0.0,
                    "cost_per_conversion": float(row.metrics.cost_per_conversion / 1_000_000) if hasattr(row.metrics, "cost_per_conversion") else 0.0,
                    "imported_at": imported_at
                })

            logger.info(f"   ‚úÖ Sucesso na tentativa {attempt}")
            return data
            
        except Exception as e:
            error_message = str(e)
            logger.warning(f"   ‚ö†Ô∏è Erro na tentativa {attempt}/{max_retries}: {error_message}")
            
            # Se for o √∫ltimo retry, lan√ßa o erro
            if attempt == max_retries:
                logger.error(f"   ‚ùå Todas as {max_retries} tentativas falharam para {customer_id}")
                raise
            
            # Backoff exponencial: espera 2^attempt segundos (2, 4, 8...)
            wait_time = 2 ** attempt
            logger.info(f"   ‚è≥ Aguardando {wait_time} segundos antes da pr√≥xima tentativa...")
            time.sleep(wait_time)
    
    return []

def save_to_bigquery(data):
    """Salva dados no BigQuery."""
    if not data:
        logger.warning("‚ö†Ô∏è Nenhum dado para inserir.")
        return

    check_table_exists()

    # Converter para DataFrame
    df = pd.DataFrame(data)

    # ‚úÖ Corrigir o tipo da coluna 'date'
    df["date"] = pd.to_datetime(df["date"]).dt.date
    
    # ‚úÖ Garantir que imported_at seja timestamp UTC (BigQuery requer UTC)
    # Converter timezone-aware datetime para UTC e depois remover timezone info
    df["imported_at"] = pd.to_datetime(df["imported_at"]).dt.tz_convert('UTC').dt.tz_localize(None)

    # ‚úÖ Reordenar colunas
    desired_order = [
        "account_name",
        "account_id",
        "campaign_id",
        "campaign_name",
        "date",
        "hour",
        "moeda",
        "budget",
        "spend",
        "clicks",
        "cpc",
        "impressions",
        "ctr",
        "conversions",
        "cost_per_conversion",
        "imported_at"
    ]
    df = df[desired_order]
    
    # Log de informa√ß√µes sobre os dados
    logger.info(f"   üìä Total de linhas: {len(df)}")
    logger.info(f"   üìÖ Exemplo de imported_at: {df['imported_at'].iloc[0] if len(df) > 0 else 'N/A'}")
    logger.info(f"   üî¢ Tipos de dados:")
    for col in ['date', 'hour', 'imported_at']:
        logger.info(f"      - {col}: {df[col].dtype}")

    # Enviar ao BigQuery (WRITE_APPEND)
    bq_client = get_bq_client()
    job_config = bigquery.LoadJobConfig(write_disposition="WRITE_APPEND")
    job = bq_client.load_table_from_dataframe(df, BIGQUERY_TABLE_ID, job_config=job_config)
    job.result()

    logger.info("‚úÖ Dados inseridos com sucesso no BigQuery!")
    logger.info(f"   üìã Tabela: {BIGQUERY_TABLE_ID}")
    logger.info(f"   üìä Registros inseridos: {len(df)}")

# ------------------------------------------------------------------------------
# FUN√á√ÉO PRINCIPAL
# ------------------------------------------------------------------------------
def ca_google_ads_today(event=None, context=None):
    """
    Fun√ß√£o principal para coleta de dados do Google Ads.
    Compat√≠vel com Cloud Functions e GitHub Actions.
    """
    logger.info("üöÄ Iniciando coleta de dados do Google Ads...")
    logger.info("üìÖ Data (ontem): %s", ontem)

    try:
        # ‚úÖ PASSO 0: Verificar vers√µes das bibliotecas
        log_library_versions()
        
        # ‚úÖ PASSO 1: Verificar secrets e configura√ß√µes
        logger.info("=" * 80)
        logger.info("üîê ETAPA 1: VERIFICA√á√ÉO DE SECRETS")
        logger.info("=" * 80)
        
        if not verify_secrets():
            error_msg = "‚ùå Falha na verifica√ß√£o de secrets. Abortando execu√ß√£o."
            logger.error(error_msg)
            raise ValueError(error_msg)
        
        logger.info("‚úÖ Secrets verificados com sucesso! Prosseguindo...\n")
        
        # ‚úÖ PASSO 2: Criar cliente Google Ads
        logger.info("=" * 80)
        logger.info("üîß ETAPA 2: CRIANDO CLIENTE GOOGLE ADS")
        logger.info("=" * 80)
        client = get_google_ads_client()
        logger.info("‚úÖ Cliente Google Ads criado com sucesso!\n")

        # ‚úÖ PASSO 3: Coletar dados das contas
        logger.info("=" * 80)
        logger.info("üìä ETAPA 3: COLETANDO DADOS DAS CONTAS DO GOOGLE ADS")
        logger.info("=" * 80)
        logger.info(f"Total de contas a processar: {len(CUSTOMER_IDS)}\n")

        all_data = []
        success_count = 0
        error_count = 0
        errors_detail = []

        for idx, customer_id in enumerate(CUSTOMER_IDS, 1):
            logger.info(f"üîç [{idx}/{len(CUSTOMER_IDS)}] Processando customer_id: {customer_id}")
            try:
                data = get_google_ads_data(client, customer_id, max_retries=3)
                if data:
                    logger.info(f"   ‚úÖ {len(data)} registros extra√≠dos")
                    all_data.extend(data)
                    success_count += 1
                else:
                    logger.warning(f"   ‚ö†Ô∏è Nenhum dado encontrado")
            except Exception as e:
                error_msg = str(e)
                logger.error(f"   ‚ùå Erro: {error_msg}")
                error_count += 1
                errors_detail.append({
                    "customer_id": customer_id,
                    "error": error_msg
                })
            
            # Pequeno delay entre requisi√ß√µes para evitar rate limiting
            if idx < len(CUSTOMER_IDS):
                logger.info("   ‚è≥ Aguardando 1 segundo antes da pr√≥xima conta...")
                time.sleep(1)
            
            logger.info("")  # linha em branco para separar

        # Resumo da coleta
        logger.info("=" * 80)
        logger.info("üìà RESUMO DA COLETA")
        logger.info("=" * 80)
        logger.info(f"‚úÖ Contas processadas com sucesso: {success_count}/{len(CUSTOMER_IDS)}")
        logger.info(f"‚ùå Contas com erro: {error_count}/{len(CUSTOMER_IDS)}")
        logger.info(f"üìä Total de registros coletados: {len(all_data)}")
        
        # Detalhar erros se houver
        if errors_detail:
            logger.info("\nüìã Detalhes dos erros:")
            for error_info in errors_detail:
                logger.info(f"   - Customer ID {error_info['customer_id']}: {error_info['error']}")
        
        logger.info("=" * 80 + "\n")

        if all_data:
            # ‚úÖ PASSO 4: Salvar no BigQuery
            logger.info("=" * 80)
            logger.info("üíæ ETAPA 4: SALVANDO DADOS NO BIGQUERY")
            logger.info("=" * 80)
            save_to_bigquery(all_data)
            logger.info("‚úÖ Dados salvos com sucesso!\n")
        else:
            logger.warning("‚ö†Ô∏è Nenhum dado extra√≠do de nenhuma conta. Nada para salvar no BigQuery.")

        logger.info("=" * 80)
        logger.info("üéâ PROCESSAMENTO CONCLU√çDO COM SUCESSO")
        logger.info("=" * 80)
        return "‚úÖ Processamento conclu√≠do com sucesso."
    
    except Exception as e:
        logger.error("\n" + "=" * 80)
        logger.error("üí• ERRO CR√çTICO NA EXECU√á√ÉO")
        logger.error("=" * 80)
        logger.error("Tipo do erro: %s", type(e).__name__)
        logger.error("Mensagem: %s", str(e))
        logger.error("=" * 80)
        raise

# ------------------------------------------------------------------------------
# EXECU√á√ÉO LOCAL
# ------------------------------------------------------------------------------
if __name__ == "__main__":
    start_time = time.time()
    logger.info("\n" + "=" * 80)
    logger.info("üöÄ INICIANDO EXECU√á√ÉO LOCAL - GOOGLE ADS HOURLY HISTORICAL DATA")
    logger.info("=" * 80)
    logger.info("üìÖ Data (ontem): %s", ontem)
    logger.info("üè¢ Ambiente: Local/GitHub Actions")
    logger.info("=" * 80 + "\n")
    
    try:
        result = ca_google_ads_today()
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        logger.info("=" * 80)
        logger.info("üéØ RESUMO FINAL DA EXECU√á√ÉO")
        logger.info("=" * 80)
        logger.info("‚úÖ Status: SUCESSO")
        logger.info("‚è±Ô∏è Tempo total: %.2f segundos", execution_time)
        logger.info("üìÖ Data processada (ontem): %s", ontem)
        logger.info("üî¢ Contas configuradas: %d", len(CUSTOMER_IDS))
        logger.info("=" * 80)
        
    except Exception as e:
        end_time = time.time()
        execution_time = end_time - start_time
        
        logger.error("\n" + "=" * 80)
        logger.error("üéØ RESUMO FINAL DA EXECU√á√ÉO")
        logger.error("=" * 80)
        logger.error("‚ùå Status: FALHA")
        logger.error("‚è±Ô∏è Tempo at√© falha: %.2f segundos", execution_time)
        logger.error("üí• Erro: %s", str(e))
        logger.error("=" * 80)
        raise

