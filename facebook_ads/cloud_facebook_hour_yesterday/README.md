# Facebook Ads Hourly Data - GitHub Actions

Este projeto coleta dados de performance de campanhas do Facebook **agregados por hora** e os envia para o BigQuery usando GitHub Actions.

## üéØ Objetivo

Coletar m√©tricas hor√°rias de campanhas do Facebook de **ONTEM** e armazenar no BigQuery para an√°lise hist√≥rica.

## üìÖ Per√≠odo de Coleta

- **Data coletada:** ONTEM (date_preset: "yesterday")
- **Exemplo:** Se hoje √© 07/01/2026, coleta dados de 06/01/2026
- **Breakdown:** Por hora (hourly_stats_aggregated_by_advertiser_time_zone)

## üìä Dados Coletados

### Campos extra√≠dos:
- `site_name` - Primeiros 2 caracteres do nome da campanha
- `account_name` - Nome da conta
- `account_id` - ID da conta
- `date` - Data dos dados
- `time_interval` - Intervalo hor√°rio (0-23)
- `impressions` - N√∫mero de impress√µes
- `spend` - Gasto total
- `clicks` - N√∫mero de cliques em links
- `imported_at` - Timestamp da importa√ß√£o

## üóÑÔ∏è Destino

**BigQuery:**
- **Tabela:** `data-v1-423414.test.cloud_facebook_hour_historical`
- **Modo de escrita:** `WRITE_APPEND` (adiciona novos dados, acumula hist√≥rico)

## ‚öôÔ∏è Configura√ß√£o

### Secrets Necess√°rios (GitHub Actions)

#### `SECRET_GOOGLE_SERVICE_ACCOUNT`
Credenciais do Google Cloud Service Account (formato JSON):
```json
{
  "type": "service_account",
  "project_id": "seu-project-id",
  "private_key_id": "...",
  "private_key": "-----BEGIN PRIVATE KEY-----\n...\n-----END PRIVATE KEY-----\n",
  "client_email": "...",
  "client_id": "...",
  "auth_uri": "https://accounts.google.com/o/oauth2/auth",
  "token_uri": "https://oauth2.googleapis.com/token",
  "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
  "client_x509_cert_url": "..."
}
```

### Grupos de Contas Configurados

O script processa m√∫ltiplos grupos de contas Facebook em paralelo:
- **CASF A, A2**: 15 contas
- **CASF B, B2**: 34 contas
- **CASF C, C2, C3**: 41 contas
- **Cloud Arbitration 1, 2, 3**: 9 contas
- **CAAG A, B**: 6 contas
- **Nassovia A**: 3 contas

**Total**: 108 contas em 13 grupos

## üöÄ Execu√ß√£o

### GitHub Actions (Autom√°tico)
- **Agendamento:** Diariamente √†s 07:00 BRT (10:00 UTC)
- **Workflow:** `.github/workflows/cloud_facebook_hour_yesterday.yml`

### Execu√ß√£o Manual
```bash
# Configurar vari√°veis de ambiente
export SECRET_GOOGLE_SERVICE_ACCOUNT='{"type":"service_account",...}'

# Executar
python main.py
```

## üì¶ Depend√™ncias

Instale as depend√™ncias com:
```bash
pip install -r requirements.txt
```

Principais bibliotecas:
- `google-cloud-bigquery==3.15.0` - Cliente BigQuery
- `google-cloud-storage==2.13.0` - Cliente Google Cloud Storage
- `aiohttp==3.9.1` - Cliente HTTP ass√≠ncrono
- `pandas==2.1.4` - Manipula√ß√£o de dados
- `pytz==2023.3` - Timezones
- `functions-framework==3.5.0` - Suporte para Cloud Functions

## üîÑ Fluxo de Execu√ß√£o

1. ‚úÖ **Verifica√ß√£o de Credenciais** - Valida se as credenciais est√£o configuradas
2. ‚úÖ **Cria√ß√£o de Clientes** - Inicializa cliente BigQuery
3. ‚úÖ **Coleta de Dados** - Para cada grupo e conta:
   - Faz requisi√ß√£o √† API do Facebook Graph
   - Usa retry logic (3 tentativas) para resili√™ncia
   - Processa em lotes de 5 contas por vez
   - Aguarda delays configur√°veis entre requisi√ß√µes
4. ‚úÖ **Processamento** - Agrega dados por hora
5. ‚úÖ **Salvamento no BigQuery** - Insere todos os dados coletados

## üõ°Ô∏è Resili√™ncia

O script implementa:
- **Retry Logic:** 3 tentativas com backoff exponencial (2s, 4s, 8s)
- **Processamento Ass√≠ncrono:** M√∫ltiplos grupos processados em paralelo
- **Rate Limiting:** Delays autom√°ticos entre requisi√ß√µes
- **Batch Processing:** Processa contas em lotes de 5 para evitar sobrecarga
- **Tratamento de erros:** Continua processando mesmo se uma conta falhar

## ‚ö° Performance

- **Processamento Ass√≠ncrono:** Usa `aiohttp` para requisi√ß√µes paralelas
- **Conex√µes Otimizadas:** 100 conex√µes totais, 30 por host
- **Timeout:** 60 segundos por requisi√ß√£o
- **Configura√ß√µes de Paralelismo:**
  - `MAX_WORKERS`: 15
  - `REQUEST_DELAY`: 0.35s
  - `ACCOUNT_DELAY`: 0.7s
  - `RATE_LIMIT_DELAY`: 30.0s

## üìù Logs

O script gera logs detalhados:
```
üîÑ Processando 13 grupos em paralelo para m√°xima velocidade
üìä [casf_a] Processando 7 contas...
‚úÖ [casf_a] Processamento conclu√≠do: 150 registros
üìä Total de dados coletados: 2000 registros
üìà Dados processados por hora: 500 registros
‚òÅÔ∏è Fazendo upload para BigQuery: data-v1-423414.test.cloud_facebook_hour_historical
‚úÖ Dados enviados com sucesso para o BigQuery!
üéâ Execu√ß√£o conclu√≠da com sucesso!
```

## ‚ö†Ô∏è Notas Importantes

1. **Data de coleta:** O script coleta dados de ONTEM (date_preset: "yesterday")
2. **Timezone:** Usa timezone de S√£o Paulo (America/Sao_Paulo) para `imported_at`
3. **Modo de escrita:** APPEND (adiciona novos dados, acumula hist√≥rico completo)
4. **Tabela √∫nica:** Todos os grupos usam a mesma tabela `cloud_facebook_hour_historical`

## üîç Troubleshooting

### Erro: "SECRET_GOOGLE_SERVICE_ACCOUNT n√£o encontrado"
- Verifique se o secret est√° configurado no GitHub Actions
- Certifique-se que o JSON est√° v√°lido

### Erro de autentica√ß√£o BigQuery
- Verifique se `SECRET_GOOGLE_SERVICE_ACCOUNT` est√° correto
- Certifique-se que a Service Account tem permiss√µes de escrita no BigQuery

### Rate Limiting do Facebook
- O script j√° inclui delays autom√°ticos
- Se necess√°rio, ajuste `REQUEST_DELAY` e `ACCOUNT_DELAY` no c√≥digo

### Timeout
- Timeout configurado para 60 segundos por requisi√ß√£o
- Se necess√°rio, ajuste em `aiohttp.ClientTimeout(total=60)`

## üìä Estrutura da Tabela BigQuery

```sql
CREATE TABLE `data-v1-423414.test.cloud_facebook_hour_historical` (
  site_name STRING,
  account_name STRING,
  account_id STRING,
  date STRING,
  time_interval STRING,
  impressions INT64,
  spend FLOAT64,
  clicks INT64,
  imported_at STRING
);
```

## üîß Configura√ß√£o para Produ√ß√£o

### ‚úÖ J√° Configurado

1. **Credenciais GCP**: ‚úÖ Configurado para usar secrets do GitHub via `SECRET_GOOGLE_SERVICE_ACCOUNT`
2. **Workflow GitHub Actions**: ‚úÖ Criado e configurado para rodar √†s 07h BRT
3. **Modo de Escrita**: ‚úÖ WRITE_APPEND ativado para acumular hist√≥rico
4. **Processamento Ass√≠ncrono**: ‚úÖ Otimizado para m√°xima performance
5. **Tabela √önica**: ‚úÖ Todos os grupos usam `cloud_facebook_hour_historical`

### ‚ö†Ô∏è Opcional

1. **Tokens de Acesso Facebook**: Os tokens do Facebook est√£o hardcoded no arquivo. Considere mov√™-los para vari√°veis de ambiente ou secrets do GitHub para maior seguran√ßa

## üìà Status do Projeto

- [x] Criar workflow do GitHub Actions ‚úÖ
- [x] Configurar agendamento autom√°tico (07h BRT diariamente) ‚úÖ
- [x] Configurar credenciais do Google Cloud ‚úÖ
- [x] Implementar processamento ass√≠ncrono ‚úÖ
- [x] Configurar tabela √∫nica para todos os grupos ‚úÖ
- [x] Criar README completo ‚úÖ
- [ ] Mover tokens do Facebook para secrets (opcional)
- [ ] Documentar estrutura da tabela BigQuery (opcional)

---

**√öltima atualiza√ß√£o:** Janeiro 2026

